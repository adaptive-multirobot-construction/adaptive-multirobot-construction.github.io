<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Feedback-driven adaptive multi-robot timber construction </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.adelresearchgroup.org/">
        <span>
          <img src="static/images/arg.png" alt="Home" style="height: 1.5rem; width: auto;">
        </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://www.adelresearchgroup.org/">
            ARG
          </a>
<!--           <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a> -->
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Feedback-driven adaptive multi-robot timber construction </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=IgVwlIcAAAAJ&hl=en&oi=ao">Arash Adel</a><sup>a,b,*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=9vopSH0AAAAJ&hl=en">Daniel Ruan</a><sup>a,b</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=-d7pwn4AAAAJ&hl=en&oi=ao">Wesley McGee</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=bCqEHLsAAAAJ&hl=en">Salma Mozaffari</a><sup>a,b</sup>
            </span>
<!--             <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>corresponding author</span><br>
            <span class="author-block"><sup>a</sup>Princeton University, Princeton, NJ 08544, USA</span><br>
            <span class="author-block"><sup>b</sup>University of Michigan, Ann Arbor, MI 48109, USA</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://www.sciencedirect.com/science/article/pii/S0926580524001808"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
<!--               <span class="link-block">
                <a href="https://www.sciencedirect.com/science/article/pii/S0926580524001808"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=Rbo6WDL-p0E"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
<!--               <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
      <div class="has-text-centered" style="margin-top: 2rem;">
  <img src="static/images/logos.jpg" alt="Logo" style="height: 60px; width: auto;">
</div>
    </div>
  </div>
</section>





<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title is-3">Video</h2> -->
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/Rbo6WDL-p0E?rel=0&amp;showinfo=0"   
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
    <!-- https://youtu.be/Rbo6WDL-p0E -->



    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Automation and robotics are anticipated to play a crucial role in addressing challenges confronting the construction industry, such as low productivity, workforce shortages, and physically demanding labor. However, a critical challenge in construction robotics has been the development of robust adaptive control to deal with uncertainties inherent in construction, such as material imperfections, multi-robot calibration, and fabrication inaccuracies. To address this challenge, we present a feedback-driven framework consisting of two complementary adaptive fabrication methods, pose-based and topology-based, incorporating perception, reasoning, and acting to handle uncertainties in multi-robot timber construction. We evaluate our framework through buildingscale experiments, quantifying their deviations from their as-planned digital models. Our results indicate that our pose-based method significantly decreased deviations compared to a benchmark when applied to nail-laminated timber panels, and our topology-based method enabled robust multi-robot construction of a timber frame wall. Altogether, this research contributes to flexible, accurate, and robust construction employing multi-robot systems.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
<!--     <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/17SX5MXv6mo?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


 -->

 <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Multi-robot timber fabrication setup and process

</h2>

        <div class="content has-text-justified">
          <p>
          Our fabrication setup (<b>Fig. 1</b>) comprises two six-axis industrial robotic arms with a payload of 120 kg and a reach of 2700 mm, mounted on parallel linear tracks. Each robotic arm has access to an automatic tool-changing station, which enables seamless end-effector swapping. In our experiments, each robotic arm utilizes a custom pneumatically controlled gripper end effector to grasp lumber elements with varying profile dimensions (e.g., nominal 2×4 or 4×6). Additionally, we used a 2D laser profiler3 for all scanning operations (e.g., scanning the as-built subassembly), and the robotic arms swapped out their grippers with this laser profiler whenever necessary during the fabrication process. We also designed, engineered, and built a three-axis CNC saw and mounted it between the two tracks to be accessible by both robots. The saw has a blade with a radius of 300 mm and a kerf of 6.25 mm. The saw blade can rotate -180 to +180 degrees and tilt between 0 and 45 degrees, enabling perpendicular cuts as well as a wide range of miter and compound miter cuts.
          </p>

        <figure class="image">
          <img src="static/images/Fig1.jpg"
               alt="Fabrication setup"
               style="width: 700px; height: auto;">
          <figcaption class="has-text-centered is-size-6 mt-2">
            <b>Fig. 1.</b> Multi-robot timber fabrication setup.
          </figcaption>
        </figure>

        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


 <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Bi-directional digital design-to-fabrication workflow
</h2>

        <div class="content has-text-justified">
          <p>
            <b>The bi-directional digital design-to-fabrication workflow (Fig.2)</b> is implemented as a loop, including a forward and a backward process. The <b>forward process</b> derives the necessary poses and cut parameters from the digital model of each timber element, which our control algorithm can interpret for trajectory planning, saw configuration, and gripper state. The planned trajectory, saw configuration, and gripper states are then automatically post-processed into KUKA Robot Language (KRL) code to be executed by the robotic arms and the CNC saw.
            <b>The backward workflow process</b> facilitates the necessary feedback into the as-planned digital model based on perceived as-built conditions and enables adaptive correction of the as-planned model for future fabrication steps. We investigated and tested <b>two adaptive methods</b> for our framework: <b>pose-based</b> and <b>topology-based</b> adaptive fabrication.
          </p>


            <figure class="image">
              <img src="static/images/Fig2.jpg"
                   alt="Fabrication setup"
                   style="width: 700px; height: auto;">
              <figcaption class="has-text-centered is-size-6 mt-2">
                <b>Fig. 2.</b> Overview of the bi-directional digital design-to-fabrication workflow and process.
              </figcaption>
            </figure>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>










 <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Pose-based adaptive fabrication
</h2>

        <div class="content has-text-justified">
          <p>
            By tracking element poses, we formalize an adaptive fabrication method for minimizing deviations between the as-planned digital model and the as-built subassembly. We first formalize the fabrication process into a state-space representation, which sets the foundation for both adaptive methods. We then expand on how a robot perceives a pose by scanning the element extents and reconstructing the element geometry (<b>Fig. 3</b>). Next, we implement a direct Iterative Learning Control (ILC) algorithm to minimize the tracking error between the reference and perceived poses, which iteratively self-corrects for any fabrication inaccuracies in the robotic setup. Finally, we develop the method for adaptively updating an element’s reference pose based on the current as-built conditions, enabling multi-robot coordination with a common localization reference. The overall control process is visualized in <b>Fig. 4</b>.
          </p>

            <figure class="image">
              <img src="static/images/Fig3.jpg"
                   alt="Fabrication setup"
                   style="width: 700px; height: auto;">
              <figcaption class="has-text-centered is-size-6 mt-2">
                <b>Fig. 3.</b> Element pose perception process, with scanning of the element extents (left) and processing of the resulting point cloud to reconstruct the element geometry.
                  (right).
              </figcaption>
            </figure>

            <figure class="image">
                <img src="static/images/Fig4.jpg"
                     alt="Fabrication setup"
                     style="width: 700px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 4.</b> Overview of the pose-based adaptive fabrication method, including the developed ILC and adaptive pose correction processes.
                </figcaption>
            </figure>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>








 <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">NLT panel experiment
</h2>

        <div class="content has-text-justified">
          <p>
            In the first experiment, the task was to fabricate a flat, 1-m-wide nail-laminated timber (NLT) panel by perpendicularly cutting, stacking, and fastening 10 elements cut from standard 2 × 4 dimensional lumber, alternating between the two robots. In applying the pose-based adaptive fabrication method, we tested two scenarios: <b>(1)</b> neither robot adapts (base case used for benchmarking, and <b>(2)</b> both robots utilizing the pose-based adaptive fabrication method (<b>Fig. 5</b>). While this assembly task is relatively simple, the experiment demonstrates the inherent additional deviations that can occur in a multi-robot assembly system due to discrepancies of their world frames, and how we can correct for them within a restricted number of degrees of freedom (planar translation and rotation).
          </p>

          <figure class="image">
                <img src="static/images/Fig5.jpg"
                     alt="Fabrication setup"
                     style="width: 700px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 5.</b> (left) The benchmark experimental scenario with both robots alternating to assemble an NLT panel without adaptation, (right) The adaptive experimental scenario, with both robots alternating to assemble an NLT panel using the developed pose-based adaptive fabrication method.
                </figcaption>
          </figure>

        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>










 <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Topology-based adaptive fabrication
</h2>

        <div class="content has-text-justified">
          <p>
            We also formalize an adaptive fabrication method for minimizing deviations at the joints between elements using the topology of the as-planned digital model. Here, we refer to topology as the relationship between elements within a subassembly and how elements must be fastened together to form a structural connection. This approach acknowledges that ensuring a proper connection with current as-built elements is more important than their absolute pose for many elements in an assembly task. For example, a stud in a timber wall frame should be flush with the wall's surface, and its ends should be cut flat against the top and bottom plates. The stud’s pose has a small degree of freedom within these constraints. We first formalize the cut parameters for an element. Then, we scan a patch of the as-built structure, namely the contact surfaces where the element must interface. Finally, we update the element’s combined state (pose and cut parameters) to fit the scanned contact surfaces (<b>Fig. 7</b>). The overall control process is visualized in <b>Fig. 8</b>.
          </p>

          <figure class="image">
                <img src="static/images/Fig7.jpg"
                     alt="Fabrication setup"
                     style="width: 700px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 7.</b> Element contact patch perception process, with locating the as-planned contact patches (left), scanning of the current as-built subassembly (middle), and processing of the resulting point cloud to extract the updated cut parameters (right).
                </figcaption>
          </figure>
          <figure class="image">
                <img src="static/images/Fig8.jpg"
                     alt="Fabrication setup"
                     style="width: 700px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 8.</b> Overview of the topology-based adaptive fabrication method.
                </figcaption>
          </figure>


        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Wall module experiment
</h2>

        <div class="content has-text-justified">
          <p>
            In the second experiment, the robotic setup was tasked to fabricate a full-scale spatial timber wall module (<b>Fig. 9</b>). The module consists of 13 elements connected via butt joints and measures 2.05 m long by 2.32 m tall. This experiment demonstrates the potential and necessity of multiple robots during fabrication to stabilize the in-progress subassembly during each step. In this type of assembly, it is common for the floor and top plate to have some material deformation, causing parts collision when inserting the studs without adaptation during robotic fabrication and interrupting the fabrication process. In this experiment, we utilized the developed topology-based adaptive fabrication method to ensure the assemblability of the wall module. 
          </p>
          <figure class="image">
                <img src="static/images/Fig9.png"
                     alt="Fabrication setup"
                     style="width: 600px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 9.</b> The second experiment with both robots cooperatively assembling a full-scale timber wall frame utilizing the topology-based adaptive fabrication method,
                  showing the fabrication steps (top) and the finished module (bottom).
                </figcaption>
          </figure>

        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <p>
            After completing each subassembly in both experiments, we scan the as-built structure using the laser profiler end effector to collect a high-resolution point cloud, which is used in the following section to analyze the surface deviation from the as-planned digital model. The profile resolution of the laser profiler is 0.150 mm, and the depth resolution is 0.019 mm, with a linearity of ±0.01% of the measurement range. To scan the structure, we complete multiple passes of the laser profiler in overlapping bands. These partial scans are then stitched together using the recorded pose of the laser at each scan. 
          <p>
          <p>
          <b>Fig. 10</b> shows surface deviations between the as-built <b>NLT panel</b> and the as-planned digital model for each scenario in a heat map and plotted in a histogram with a bin size of 0.1 mm. The average surface deviation of the benchmark scenario is 1.42 mm, with a median of 1.12 mm and a standard deviation of 1.16 mm. The average surface deviation of the adaptive scenario is 0.73 mm, with a median of 0.67 mm and a standard deviation of 0.58 mm. <b>Fig. 11</b> shows the evaluated point cloud deviation between the final as-built <b>wall module</b> and the as-planned digital model. The deviations are visualized as a heat map and plotted in a histogram with a bin size of 0.2 mm. The average deviation is 2.43 mm, with a median of 2.06 mm and a standard deviation of 1.97 mm.
          </p>

          <figure class="image">
                <img src="static/images/Fig10.jpg"
                     alt="Fabrication setup"
                     style="width: 800px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 10.</b> Deviation from each point in the scanned point cloud of the as-built subassembly to the as-planned digital model, visualized in a histogram (top) and a heat map (bottom) for the benchmark scenario with no adaptation (a) and with both robots utilizing the pose-based adaptive fabrication method (b). 
                </figcaption>
          </figure>
                    <figure class="image">
                <img src="static/images/Fig11.jpg"
                     alt="Fabrication setup"
                     style="width: 500px; height: auto;">
                <figcaption class="has-text-centered is-size-6 mt-2">
                  <b>Fig. 11.</b> Deviation from the scanned point cloud of the as-built wall module to the best-fit transformation of the as-planned digital model.
                </figcaption>
          </figure>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>









<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Conclusion</h2>

        <div class="content has-text-justified">
          <p>
          Our proposed framework relies on using the as-built subassembly as a localization target for self-calibration and fabrication adjustment, avoiding issues of calibrating to a common-world coordinate system using external measurement equipment. In particular, our developed <b>pose-based adaptive method</b> proved effective in decreasing deviations of the as-built NLT panel from its as-planned digital model for a cooperative assembly task performed by two robots. Furthermore, our <b>topology-based adaptive method</b> enabled the successful completion of a wall module, which was fabricated cooperatively by two robots. <b>This research contributes to the body of knowledge required to facilitate flexible and accurate cooperative multi-robot construction at the building scale.</b>
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Acknowledgments</h2>

        <div class="content has-text-justified">
          <p>
          This research was supported by the National Science Foundation (NSF, Award No. 2128623) and the Taubman College of Architecture and Urban Planning (TCAUP) at the University of Michigan (U-M). Empirical physical prototyping research was conducted at the University of Michigan. The authors would like to thank Rachael Henry for her invaluable support at the TCAUP FABLab.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>




























<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{adel2024feedback,
  title={Feedback-driven adaptive multi-robot timber construction},
  author={Adel, Arash and Ruan, Daniel and McGee, Wesley and Mozaffari, Salma},
  journal={Automation in Construction},
  volume={164},
  pages={105444},
  year={2024},
  publisher={Elsevier},
  url={https://doi.org/10.1016/j.autcon.2024.105444}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
<!--       <a class="icon-link"
         href="https://www.sciencedirect.com/science/article/pii/S0926580524001808">
        <i class="fas fa-file-pdf"></i>
      </a> -->
<!--       <a class="icon-link" href="https://www.adelresearchgroup.org/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template was adapted from  <a
              href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
